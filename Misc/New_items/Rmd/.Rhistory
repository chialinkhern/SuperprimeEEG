# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+10)&(matched_abs$conc>conc-10)&(matched_abs$word_len<len+1)&(matched_abs$word_len>len-1)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+10)&(matched_abs$conc>conc-10)&(matched_abs$word_len<len+1)&(matched_abs$word_len>len-1)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+20)&(matched_abs$conc>conc-20)&(matched_abs$word_len<len+1)&(matched_abs$word_len>len-1)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+15)&(matched_abs$conc>conc-15)&(matched_abs$word_len<len+1)&(matched_abs$word_len>len-1)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+10)&(matched_abs$conc>conc-10)&(matched_abs$word_len<len+3)&(matched_abs$word_len>len-3)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+10)&(matched_abs$conc>conc-10)&(matched_abs$word_len<len+2)&(matched_abs$word_len>len-2)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+15)&(matched_abs$conc>conc-15)&(matched_abs$word_len<len+3)&(matched_abs$word_len>len-3)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+15)&(matched_abs$conc>conc-15)&(matched_abs$word_len<len+3)&(matched_abs$word_len>len-3)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
View(old_abs)
write.table(new_abs,"../data/new_abstracts.csv")
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats_old = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats_old
conc = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
desc_stats_new = rbind(conc, word_len)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats_new
conc = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
desc_stats_old = rbind(conc, word_len)
colnames(desc_stats_old) = c("min", "max", "mean")
desc_stats_old
conc = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
desc_stats_new = rbind(conc, word_len)
colnames(desc_stats_new) = c("min", "max", "mean")
desc_stats_new
conc_old = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
conc_new = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len_old = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
word_len_new = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
desc_stats = rbind(conc_old, conc_new, word_len_old, word_len_new)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
conc_old = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
conc_new = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len_old = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
word_len_new = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
freq_old = c(round(min(old_abs$freq, na.rm=TRUE), 2), round(max(old_abs$freq, na.rm=TRUE),2), round(mean(old_abs$freq, na.rm=TRUE),2))
freq_new = c(round(min(new_abs$freq, na.rm=TRUE), 2), round(max(new_abs$freq, na.rm=TRUE),2), round(mean(new_abs$freq, na.rm=TRUE),2))
desc_stats = rbind(conc_old, conc_new, word_len_old, word_len_new)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
conc_old = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
conc_new = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len_old = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
word_len_new = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
freq_old = c(round(min(old_abs$freq, na.rm=TRUE), 2), round(max(old_abs$freq, na.rm=TRUE),2), round(mean(old_abs$freq, na.rm=TRUE),2))
freq_new = c(round(min(new_abs$freq, na.rm=TRUE), 2), round(max(new_abs$freq, na.rm=TRUE),2), round(mean(new_abs$freq, na.rm=TRUE),2))
desc_stats = rbind(conc_old, conc_new, word_len_old, word_len_new)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
conc_old = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
conc_new = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len_old = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
word_len_new = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
freq_old = c(round(min(old_abs$freq, na.rm=TRUE), 2), round(max(old_abs$freq, na.rm=TRUE),2), round(mean(old_abs$freq, na.rm=TRUE),2))
freq_new = c(round(min(new_abs$freq, na.rm=TRUE), 2), round(max(new_abs$freq, na.rm=TRUE),2), round(mean(new_abs$freq, na.rm=TRUE),2))
desc_stats = rbind(conc_old, conc_new, word_len_old, word_len_new, freq_old, freq_new)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
# loading in old items
old_abs = read.table("../data/old_abstracts.csv", sep=",", header=TRUE)
old_abs$conc[old_abs$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_abs = read.table("../data/matched_abstracts.csv", sep=",", header=TRUE)
# filtering out words that are already in old set
matched_abs = subset(matched_abs, !(matched_abs$word %in% old_abs$word))
# log-transforming frequencies
old_abs$freq = log(old_abs$freq)
matched_abs$freq = log(matched_abs$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
new_abs = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_abs$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(old_abs)){
row = old_abs[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered_abs = matched_abs[((matched_abs$conc<conc+15)&(matched_abs$conc>conc-15)&(matched_abs$word_len<len+3)&(matched_abs$word_len>len-3)
&(matched_abs$freq)<freq+2.5)&(matched_abs$freq)>freq-2.5,]
sample = sample_n(filtered_abs, 1)
matched_abs = matched_abs[!(matched_abs$word == sample$word),]
new_abs = rbind(new_abs, sample)
row_index = row_index + 1
}
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
# old len distribution
hist(old_abs$word_len, main="Word length of old abstract targets", xlab="Word Length")
# new len distribution
hist(new_abs$word_len, main="Word length of new abstract targets", xlab="Word Length")
# old freq distribution
hist(old_abs$freq, main="Frequency of old abstract targets", xlab="Word Frequency")
# new freq distribution
hist(new_abs$freq, main="Frequency of new abstract targets", xlab="Word Frequency")
(new_abs)
write.table(new_abs,"../data/new_abstracts.csv")
conc_old = c(round(min(old_abs$conc, na.rm=TRUE), 2), round(max(old_abs$conc, na.rm=TRUE),2), round(mean(old_abs$conc, na.rm=TRUE),2))
conc_new = c(round(min(new_abs$conc, na.rm=TRUE), 2), round(max(new_abs$conc, na.rm=TRUE),2), round(mean(new_abs$conc, na.rm=TRUE),2))
word_len_old = c(round(min(old_abs$word_len, na.rm=TRUE), 2), round(max(old_abs$word_len, na.rm=TRUE),2), round(mean(old_abs$word_len, na.rm=TRUE),2))
word_len_new = c(round(min(new_abs$word_len, na.rm=TRUE), 2), round(max(new_abs$word_len, na.rm=TRUE),2), round(mean(new_abs$word_len, na.rm=TRUE),2))
freq_old = c(round(min(old_abs$freq, na.rm=TRUE), 2), round(max(old_abs$freq, na.rm=TRUE),2), round(mean(old_abs$freq, na.rm=TRUE),2))
freq_new = c(round(min(new_abs$freq, na.rm=TRUE), 2), round(max(new_abs$freq, na.rm=TRUE),2), round(mean(new_abs$freq, na.rm=TRUE),2))
desc_stats = rbind(conc_old, conc_new, word_len_old, word_len_new, freq_old, freq_new)
colnames(desc_stats) = c("min", "max", "mean")
desc_stats
