row_index = row_index + 1
matched_items = matched_items[!(toString(matched_items$word)==word),]
matched_items[!(toString(matched_items$word)==word),]
matched_items[!(toString(matched_items$word)=="ABASEMENT"),]
matched_items <- matched_items[!(toString(matched_items$word)==word),]
matched_items = matched_items[matched_items$word)!=word),]
matched_items = matched_items[matched_items$word!=word),]
matched_items = matched_items[matched_items$word!=word,]
matched_items = matched_items[toString(matched_items$word)!=word,]
word
matched_items[matched_items$word=="NONE",]
matched_items[matched_items$word=="ABASEMENT",]
matched_items[matched_items$word!="ABASEMENT",]
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[toString(matched_items$word)!=sampled_word,]
row_index = row_index + 1
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+10)&(matched_items$conc>conc-10)&(matched_items$word_len<len+2)&(matched_items$word_len>len-2)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% in_items$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+10)&(matched_items$conc>conc-10)&(matched_items$word_len<len+2)&(matched_items$word_len>len-2)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[toString(matched_items$word)!=sampled_word,]
matched_items[matched_items$word=="TRUISM",]
matched_items[matched_items$word!="TRUISM",]
nrows(matched_items[matched_items$word!="TRUISM",])
nrow(matched_items[matched_items$word!="TRUISM",])
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
range(matched_items$freq)
range(matched_items$conc)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
write.table(out_items, "out_items.csv")
write.table(out_items, "../data/out_items.csv")
write.table(matched_items, "../data/matched_items.csv")
View(matched_items)
write.table(matched_items, "../data/matched_abstracts.csv")
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
write.table(matched_items, "../data/matched_abstracts.csv")
write.table(out_items, "../data/out_items.csv")
test = read.table("new_abstracts.csv", header=TRUE)
test = read.table("../new_abstracts.csv", header=TRUE)
test = read.table("../data/new_abstracts.csv", header=TRUE)
test = read.table("../data/new_abstracts.csv", header=TRUE, row.names=FALSE)
test = read.table("../data/new_abstracts.csv", header=TRUE)
?read.table
test = read.table("../data/new_abstracts.csv", header=TRUE, row.names=NULL)
View(test)
test$row.names=NULL
write.table(test,"../data/new_abstracts.csv")
new_items = read.table("new_abstracts.csv", header=TRUE)
new_items = read.table("../data/new_abstracts.csv", header=TRUE)
View(new_items)
old_abs = read.table("../data/old_abstracts.csv", header=TRUE)
old_abs = read.table("../data/old_abstracts.csv", header=TRUE, sep=",")
write.table(old_abs, "../data/old_abstracts.csv")
knitr::opts_chunk$set(echo = FALSE)
new_items = read.table("../data/new_abstracts.csv", header=TRUE)
old_abs = read.table("../data/old_abstracts.csv", header=TRUE, sep=",")
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
new_abs = read.table("../data/new_abstracts.csv", header=TRUE)
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
View(new_abs)
View(new_items)
View(new_abs)
View(new_items)
View(old_abs)
old_abs = read.table("../data/old_abstracts.csv", header=TRUE)
# old conc distribution
hist(old_abs$conc, main="Concreteness values of old abstract targets", xlab="Concreteness")
# new conc distribution
hist(new_abs$conc, main="Concreteness values of new abstract targets", xlab="Concreteness")
old_abs$freq = log(old_abs$freq)
write.table(old_abstracts, "../data/old_abstracts.csv")
write.table(old_abs, "../data/old_abstracts.csv")
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
View(in_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(out_items)
# filtering out words that are already in old set
old_abs = read.table("../data/old_abstracts.csv", header=TRUE)
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
write.table(matched_items, "../data/matched_abstracts.csv")
dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(in_items)){
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
}
write.table(out_items, "../data/out_items.csv")
write.table(matched_items, "../data/matched_abstracts.csv")
View(matched_items)
View(sample)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
View(sample)
View(in_items)
View(filtered)
freq = as.numeric(row$freq)
View(sample)
View(in_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(in_items)){
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
}
row
row$freq
row
View(in_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
View(in_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
View(in_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
View(in_items)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
View(in_items)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
source('~/PycharmProjects/SuperprimeEEG/Misc/New_items/Rmd/select_new_items.R', echo=TRUE)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
# in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
# log-transforming frequencies
in_items$freq = log(in_items$freq)
matched_items$freq = log(matched_items$freq)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(in_items)){
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
}
View(in_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
View(in_items)
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
View(matched_items)
View(matched_items)
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
View(matched_items)
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE, sep=",")
matched_items$freq = log(matched_items$freq)
old_items = read.table("../data/old_abstracts.csv", header=TRUE)
View(old_items)
matched_items = subset(matched_items, !(matched_items$word %in% old_items$word))
View(matched_items)
write.table(matched_items, "../data/matched_abstracts.csv")
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
View(in_items)
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
View(matched_items)
old_abs = read.table("../data/old_abstracts.csv", header=TRUE)
View(old_abs)
new_abs = read.table("../data/new_abstracts.csv", header=TRUE)
matched_items = subset(matched_items, !(matched_items$word %in% new_abs$word))
write.table(matched_items, "../data/matched_abstracts.csv")
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
# in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(matched_items$word %in% old_abs$word))
View(matched_items)
View(in_items)
matched_items[matched_items$word=="CONFUSION",]
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(in_items)){
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
}
View(in_items)
View(row)
View(out_items)
View(matched_items)
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
# in_items$conc[in_items$conc=="-"] = NA
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# filtering out words that are already in old set
matched_items = subset(matched_items, !(ma
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(in_items)){
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
}
View(filtered)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+4)&(matched_items$word_len>len-4)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+4)&(matched_items$word_len>len-4)
&(matched_items$freq)<freq+5.5)&(matched_items$freq)>freq-5.5,]
2
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+4)&(matched_items$word_len>len-4)
&(matched_items$freq)<freq+2.5)&(matched_items$freq)>freq-2.5,]
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+4)&(matched_items$word_len>len-4)
&(matched_items$freq)<freq+3.0)&(matched_items$freq)>freq-3.0,]
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+3.5)&(matched_items$freq)>freq-3.5,]
View(filtered)
sample = sample_n(filtered, 1)
View(sample)
sample = sample_n(filtered, 1)
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
View(out_items)
write.table(out_items, "../data/out_items.csv")
View(matched_items)
write.table(out_items, "../data/out_items.csv")
write.table(matched_items, "../data/matched_abstracts.csv")
out = read.table("../data/out_items.csv")
out = read.table("../data/out_items.csv", row.names=NULL)
View(out)
out$row.names = NULL
write.table(out, "../data/out_items.csv")
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
no = read.table("../data/out_items.csv", header=TRUE)
?subset
subset(matched_items, matched_items$word!=no$word)
subset(matched_items, matched_items$word!=no$word)
View(no)
View(matched_items)
View(no)
View(matched_items)
subset(matched_items, !(matched_items$word==no$word))
!(matched_items$word==no$word)
!(matched_items$word==no$word)
(matched_items$word!=no$word)
(matched_items$word==no$word)
subset(matched_abs, !(matched_abs$word %in% no$word))
subset(matched_items, !(matched_items$word %in% no$word))
matched_items = subset(matched_items, !(matched_items$word %in% no$word))
View(matched_items)
write.table(matched_items, "../data/matched_abstracts.csv")
new_abs = read.table("../data/new_abstracts.csv", header=TRUE)
new_abs = read.table("../data/new_abstracts.csv", header=TRUE, row.names=NULL)
new_abs$row.names = NULL
View(new_abs)
write.table(new_abs, "../data/new_abstracts.csv")
table = read.table("../data/new_abstracts.csv")
View(table)
nrow(unique(table$word))
length(unique(table$word))
library(dplyr)
# loading in old items
in_items = read.table("../data/to_replace.csv", header=TRUE)
View(in_items)
# loading in items matched on concreteness and word length from MRC
matched_items = read.table("../data/matched_abstracts.csv", header=TRUE)
# sampling items from matched_abs to fit distribution of old items on: 1) concreteness, 2) word length, 3) frequency
out_items = data.frame(word=NULL, conc=NULL, word_len=NULL, freq=NULL)
mean_conc = mean(matched_items$conc)  # to deal with missing values
row_index = 1
for (row_index in 1:nrow(in_items)){
row = in_items[row_index, ]
conc = as.numeric(row$conc)
freq = as.numeric(row$freq)
if (is.na(conc)){
conc = mean_conc
}
len = as.numeric(row$word_len)
filtered = matched_items[((matched_items$conc<conc+50)&(matched_items$conc>conc-50)&(matched_items$word_len<len+3)&(matched_items$word_len>len-3)
&(matched_items$freq)<freq+3.5)&(matched_items$freq)>freq-3.5,]
sample = sample_n(filtered, 1)
sampled_word = toString(sample$word)
out_items = rbind(out_items, sample)
matched_items = matched_items[matched_items$word!=sampled_word,]
row_index = row_index + 1
}
View(sample)
View(filtered)
filtered[filtered$word=="IMMENSITY",]
rbind(out_items, filtered[filtered$word=="IMMENSITY",])
out_items = rbind(out_items, filtered[filtered$word=="IMMENSITY",])
out_items = outitems[outitems$word!="INCLEMENCY",]
out_items = out_items[outitems$word!="INCLEMENCY",]
out_items = out_items[out_items$word!="INCLEMENCY",]
out_items
out_items = out_items[out_items$word!="ALACRITY",]
out_items
sampled_word
sampled_word = "IMMENSITY"
matched_items = matched_items[matched_items$word!=sampled_word,]
write.table(out_items, "../data/out_items.csv")
write.table(matched_items, "../data/matched_abstracts.csv")
